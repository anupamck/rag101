{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "026108df-4850-4372-bda1-e7b41d5dfbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dotenv_path: /Users/anupam/Documents/Programming/rag101/.env\n",
      "Keys in .env: ['LANGSMITH_API_KEY', 'LANGSMITH_ENDPOINT', 'LANGSMITH_PROJECT', 'LANGSMITH_TRACING', 'OPENAI_API_KEY', 'POSTS_SOURCE']\n",
      "Has OPENAI_API_KEY in .env?: True\n",
      "Env OPENAI_API_KEY present?: True\n",
      "Value prefix (masked): sk-pro…\n",
      "cwd: /Users/anupam/Documents/Programming/rag101\n"
     ]
    }
   ],
   "source": [
    "## Load environment variables\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv, dotenv_values\n",
    "\n",
    "# Load with explicit path and allow override\n",
    "dotenv_path = find_dotenv(usecwd=True)\n",
    "print(\"dotenv_path:\", dotenv_path or \"NOT FOUND\")\n",
    "load_dotenv(dotenv_path=dotenv_path, override=True)\n",
    "\n",
    "# Show what was parsed from the file (safe preview)\n",
    "parsed = dotenv_values(dotenv_path) if dotenv_path else {}\n",
    "print(\"Keys in .env:\", sorted(parsed.keys()))\n",
    "print(\"Has OPENAI_API_KEY in .env?:\", \"OPENAI_API_KEY\" in parsed)\n",
    "\n",
    "val = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(\"Env OPENAI_API_KEY present?:\", val is not None)\n",
    "print(\"Value prefix (masked):\", (val[:6] + \"…\") if val else None)\n",
    "\n",
    "# Current working directory (to catch path mistakes)\n",
    "print(\"cwd:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5070809-d85c-49dc-bf5e-e525abed981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LLM model\n",
    "\n",
    "import getpass, os\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0e3e4da-a9e4-4009-b017-1c9f58eef03c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Choose embeddings\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f72129c7-a4d4-4170-b60f-728358d64a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chose vector store\n",
    "\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb89cd05-48cb-4248-8db9-130fa40193b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading posts...\n",
      "Loaded 100 posts\n",
      "Converting to Langchain documents...\n",
      "Created 100 documents\n",
      "Document Ids: ['9', '16', '18', '20', '24']\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from typing_extensions import List, TypedDict\n",
    "import json\n",
    "\n",
    "class BlogPost(TypedDict):\n",
    "    id: str\n",
    "    title: str\n",
    "    link: str\n",
    "    body: str\n",
    "\n",
    "def load_posts(json_path: str) -> List[BlogPost]:\n",
    "    # Load posts from JSON file\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def create_documents(posts: List[TypedDict]) -> List[Document]:\n",
    "    # Convert posts to Langchain documents\n",
    "    documents = []\n",
    "\n",
    "    for post in posts:\n",
    "        # Combine title and body\n",
    "        full_text = f\"Title: {post['title']}\\n\\n{post['body']}\"\n",
    "        \n",
    "        # Add metadata\n",
    "        metadata = {\n",
    "            'link': post['link'],\n",
    "            'title': post['title'],\n",
    "            'post_id': post['id'],\n",
    "        }\n",
    "        documents.append(Document(page_content=full_text, metadata=metadata, id=post['id']))\n",
    "    return documents\n",
    "\n",
    "# Load posts\n",
    "print(f\"Loading posts...\")\n",
    "posts = load_posts(os.environ.get(\"POSTS_SOURCE\"))\n",
    "print(f\"Loaded {len(posts)} posts\")\n",
    "\n",
    "# Convert to Langchain documents\n",
    "print(f\"Converting to Langchain documents...\")\n",
    "documents = create_documents(posts)\n",
    "print(f\"Created {len(documents)} documents\")\n",
    "\n",
    "# Index documents\n",
    "document_ids = vector_store.add_documents(documents=documents)\n",
    "\n",
    "print(\"Document Ids:\", document_ids[:5])\n",
    "\n",
    "# Define prompt for question-answering\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"context\"],\n",
    "    template=\"\"\"\n",
    "        Act as a conversational interface for answering questions based on the content of the blog in your knowledge base.\n",
    "\n",
    "        When posts related to a specific topic don't exist, return no results.\n",
    "                \n",
    "        Question: {question} \n",
    "        Context: {context} \n",
    "        Answer:\n",
    "        \"\"\"\n",
    ")\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State, min_similarity: float = 0.44 , max_docs: int = 8):\n",
    "    \"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "    \"\"\"\n",
    "    results = vector_store.similarity_search_with_score(state[\"question\"], k=max_docs)\n",
    "    # Filter by threshold; note: depending on backend, higher score can mean closer or farther.\n",
    "    # For Chroma + cosine similarity in LC, score is often distance; adjust comparator accordingly.\n",
    "    relevant = []\n",
    "    relevant_log = []\n",
    "    seen_keys = set()\n",
    "    for doc, score in results:\n",
    "        if score >= min_similarity:\n",
    "            key = doc.metadata.get('post_id')\n",
    "            if key in seen_keys:\n",
    "                continue\n",
    "            seen_keys.add(key)\n",
    "            relevant.append(doc)\n",
    "            relevant_log.append(f\"Doc: {doc.metadata.get('title', 'Unknown')}\\nScore: {score}\")\n",
    "    print(\"\\n\\n\".join(relevant_log))\n",
    "    return {\"context\": relevant}\n",
    "\n",
    "def generate_with_links(state: State):\n",
    "    if not state[\"context\"]:\n",
    "        \n",
    "        return {\"answer\": \"I don't know.\" + \"\\n\\nNo relevant blog posts found.\"}\n",
    "    \n",
    "    # Get the base answer\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    base_answer = response.content\n",
    "    \n",
    "    # Extract unique links from context\n",
    "    unique_links = {}\n",
    "    for doc in state[\"context\"]:\n",
    "        title = doc.metadata.get('title', 'Unknown')\n",
    "        link = doc.metadata.get('link', '')\n",
    "        if link and title not in unique_links:\n",
    "            unique_links[title] = link\n",
    "    \n",
    "    # Format links section\n",
    "    if unique_links:\n",
    "        links_section = \"\\n\\nRelevant blog posts:\\n\"\n",
    "        for title, link in unique_links.items():\n",
    "            links_section += f\"- [{title}]({link})\\n\"\n",
    "        \n",
    "        final_answer = base_answer + links_section\n",
    "    else:\n",
    "        final_answer = base_answer + \"\\n\\nNo relevant blog posts found.\"\n",
    "    \n",
    "    return {\"answer\": final_answer}\n",
    "\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate_with_links])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "355fbde5-34e6-4934-9c3b-25d1ab247477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this as a new cell after Cell 7\n",
    "# Cell 8: Create evaluation dataset\n",
    "\n",
    "import gc\n",
    "from typing import List, Dict\n",
    "\n",
    "def create_evaluation_dataset(question: str  ) -> List[Dict]:\n",
    "    \"\"\"Create evaluation dataset by running questions through the RAG system\"\"\"\n",
    "    \n",
    "    evaluation_data = []\n",
    "    # Get RAG response\n",
    "    response = graph.invoke({\"question\": question})\n",
    "    # Extract retrieved contexts (from the retrieve step)\n",
    "    retrieved_docs = response.get(\"context\", [])\n",
    "    retrieved_contexts = [doc.page_content for doc in retrieved_docs] if retrieved_docs else []\n",
    "    answer = response[\"answer\"]\n",
    "    reference = answer.split(\"\\n\\nRelevant blog posts:\")[0]  # Remove links section for reference\n",
    "    evaluation_data.append({\n",
    "            \"user_input\": question,\n",
    "            \"retrieved_contexts\": retrieved_contexts,\n",
    "            \"response\": answer,\n",
    "            \"reference\": \"\"\"\n",
    "                        To write better, consider the following insights from the blog:\n",
    "\n",
    "                        1. **Free Your Memory**: Writing helps you organize your thoughts and prioritize tasks. By putting your ideas on paper or screen, you can alleviate mental clutter and gain clarity.\n",
    "                        \n",
    "                        2. **Clarity Over Complexity**: Focus on conveying a simple and coherent message. While style can enhance your writing, it should not overshadow the clarity of your message. Aim to express your ideas in a way that even a five-year-old could understand.\n",
    "                        \n",
    "                        3. **Embrace the Process**: Understand that writer's block is a common challenge. To overcome it, prolific writers often embrace the idea of producing \"bad\" work. They recognize that creating multiple drafts, even if they are not perfect, can lead to better writing in the end.\n",
    "                        \n",
    "                        4. **Revise and Reflect**: Writing allows you to see your thoughts reflected back at you. Use this opportunity to revise and refine your ideas, which can help improve your writing skills over time.\n",
    "                        \n",
    "                        By incorporating these practices into your writing routine, you can enhance your skills and develop a more effective writing style.\n",
    "                        \"\"\",\n",
    "            \"reference_contexts\": ['Title: A writing revolution\\n\\nWhat does it mean to write? How does it help? Let me list the three things that come to my mind most easily.\\n\\nWriting frees up my memory. It keeps me from constantly juggling with information in my head. This applies to shopping lists, to-do lists, as well as to problems and concerns that plague my head. Writing helps imprison them on paper, or in more recent times, behind a screen.\\xa0It helps me look at these items and prioritize them. Whatever festers as a demon in my head eventually turns into a mere trifle after I write it down.\\n\\nSecondly, it helps me step above information and observe the patterns that emerge. Journals, blogs and articles help their authors ideate by doing so. Along with this clarity comes accountability. I am forced to think and express my ideas coherently, since it is impossible to take back what I have written.\\n\\nMost importantly, writing gives us feedback on what our thoughts look like. Unlike spoken words, which fade away, written words stare back like reflections from a mirror. Thereafter, writing enables us to go back and revise what we express, closing the loop. By editing our sentences, we are also rewiring our brain.\\n\\nWriting is one of our oldest triumphs as a species. At the same time, it is sorely underrated. Only a handful of people utilize it. There is scope yet for a writing revolution - where each person writes everyday just as surely as they bathe or brush their teeth.', \"Title: Clarity before complexity\\n\\nThe constituents of writing\\xa0are primarily a message and a writing style.\\n\\nThe message is the the idea behind the written words. It is the concept that a textbook explains, the plot that a story elaborates, the universal truth that a poem connects with, the event that a newspaper publicises or the discovery that a research paper publishes. At its crux, a message should be simple enough for a five-year old to understand.\\n\\nBut reading what a five-year old can comprehend is boring. Our mind craves complexity and sophistication. This is where style comes in.\\n\\nStyle is the choice of words used to convey the meaning. It could be simple and straightforward, or could comprise meaningful metaphors and alluring alliterations. It enables the writer to express herself while entertaining her audience and having fun. We are born puzzle-solvers and writers weave clever patterns into their writing to be more interesting. In some cases, the subject matter is abstract enough for the writer to do away with complexity completely, and adopt a simple style. This is true especially of research papers. At other times, an ornamental style enhances writing, like it does in literature.\\n\\nHowever, style and message do not get along well all the time. The need to for clarity could conflict with the complexity that style can induce. How does one prioritize?\\n\\nIn most cases, the message takes precedence over style. A simple and coherent message serves as the foundation for good writing. This would be true for all forms of writing, across literature, poetry and journalism and especially scientific writing. The trunk of the tree ought to be thicker than its branches.\\n\\nMost budding writers (including me) struggle with this prioritization. It is easier to write long sophisticated sentences than to simplify an idea. This complexity is often present because the message is not clear to the writer's himself. Sophisticated language serves as a veil for incompetence. Our minds and its mechanics are constantly tricking us (and others) into believing that we are smarter than we actually are.\\n\\nAll great writing has survived through the ages because of the coherent message beneath their intricate sentences. This is why the essence of Shakespeare's plays are simple, yet profound expressions of human nature.\\n\\nIn summary, it is better to write exactly what you mean, before resorting to fluffy and flowery, but frivolous language.\", 'Title: Deconstructing writer\\'s block\\n\\nWhat is writer\\'s block?\\n\\nIt is sitting at the table to write, but not having the words to follow through.\\xa0Anybody who has written for a while has experienced it. I have experienced it several times. I still do, as I type out these words.\\xa0More broadly, this can be called the artist\\'s block, because every creative profession seems to suffer from it. But what makes these professions unique? Why do plumbers not have plumber\\'s block? Why do carpenters not have carpenter\\'s block? Few things could be more disastrous than surgeon\\'s block!\\n\\nThis is partly because of the inherent randomness of the quality of output in creative processes.\\xa0By definition, creativity does not follow a set process. Creativity taps into a different part of the brain than the one used to perform logical, repeatable processes.\\xa0 No wonder that albums released by musicians, different works of painters, and books published by authors can vary so widely in the quality of their output.\\n\\nBut this variation alone is not enough. Additionally, there is the tendency to hold on to one\\'s last good piece of work. The tendency to allow build one\\'s perception around \"a hit\" and the tendency to not fall down from these standards. Again, the wiring of our brain is to blame here. Our tribalistic need to protect our reputation has helped us survive through our evolution. It now holds us back by inducing fear into our next creative project by whispering to us, \"if you can\\'t make it better, you are better off not trying\". Moreover, the better we get, the louder this voice whispers.\\n\\nThis combination of wide variation in quality, and clinging to one\\'s best work is what causes the crippling phenomenon of writer\\'s block. All prolific artists who overcome writer\\'s block embrace bad work. They approach the creative process like a routine. They realize that the only way to write better than their best work, is to follow through with 5 bad ones, so that the 6th work will rise to the occasion.\\n\\nAnd by doing so, they kill writer\\'s block before it kills them.\\n\\nInspiration: Seth Godin\\'s excellent podcast - Akimbo']\n",
    "        })   \n",
    "    return evaluation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a19cbb6f-106a-4c7e-8a0f-11680ee02f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Setup Ragas evaluation\n",
    "from ragas import EvaluationDataset, evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.metrics import (\n",
    "    LLMContextRecall, \n",
    "    Faithfulness, \n",
    "    FactualCorrectness,\n",
    "    AnswerRelevancy,\n",
    "    LLMContextPrecisionWithoutReference,\n",
    "    LLMContextPrecisionWithReference,\n",
    "    NonLLMContextPrecisionWithReference,\n",
    "    LLMContextRecall,\n",
    "    NonLLMContextRecall\n",
    "    \n",
    ")\n",
    "def perform_ragas_evaluation(evaluation_dataset_raw):\n",
    "    # Convert to Ragas format\n",
    "    evaluation_dataset = EvaluationDataset.from_list(evaluation_dataset_raw)\n",
    "    \n",
    "    # Setup evaluator LLM (using the same LLM for consistency)\n",
    "    evaluator_llm = LangchainLLMWrapper(llm)\n",
    "    \n",
    "    # Choose metrics (start with lighter ones to avoid memory issues)\n",
    "    metrics = [\n",
    "        AnswerRelevancy(),      # How relevant is the answer to the question\n",
    "        Faithfulness(),         # Is the answer faithful to the retrieved context\n",
    "        LLMContextPrecisionWithoutReference(), \n",
    "        # LLMContextPrecisionWithReference(),\n",
    "        # NonLLMContextPrecisionWithReference(),\n",
    "        # LLMContextRecall(),\n",
    "        # NonLLMContextRecall(),\n",
    "    ]\n",
    "    \n",
    "    print(\"Starting Ragas evaluation...\")\n",
    "    print(\"This may take a few minutes...\")\n",
    "    \n",
    "    # Add garbage collection before evaluation\n",
    "    gc.collect()\n",
    "    \n",
    "    # Run evaluation\n",
    "    result = evaluate(\n",
    "        dataset=evaluation_dataset,\n",
    "        metrics=metrics,\n",
    "        llm=evaluator_llm\n",
    "    )\n",
    "    print(\"Evaluation completed!\")\n",
    "    print(f\"Results: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bffebf03-5466-4b2e-8205-69cc260e476d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating evaluation dataset...\n",
      "Doc: A writing revolution\n",
      "Score: 0.44637411728083753\n",
      "Created 1 evaluation examples\n",
      "Here is the response: \n",
      "\n",
      " To write better, you can consider the following points derived from \"A writing revolution\":\n",
      "\n",
      "1. **Free Up Your Memory**: Writing helps you organize your thoughts and tasks, reducing the mental clutter. Make lists (shopping, to-do, etc.) to prioritize what’s important and alleviate the burden of juggling information in your head.\n",
      "\n",
      "2. **Observe Patterns**: Use writing as a tool to identify and reflect on patterns in your thoughts and ideas. This can enhance your clarity and help you express your ideas more coherently and with accountability.\n",
      "\n",
      "3. **Seek Feedback from Your Writing**: Written words serve as a reflection of your thoughts. Revisit and revise what you’ve written to gain insights and improve your expression. Editing not only refines your writing but also helps rewire your brain for clearer thinking.\n",
      "\n",
      "4. **Make Writing a Habit**: Consider incorporating writing into your daily routine, just like personal hygiene habits. Regular practice can lead to a significant improvement in your writing skills. \n",
      "\n",
      "By embracing these approaches, you can enhance your writing significantly.\n",
      "\n",
      "Relevant blog posts:\n",
      "- [A writing revolution](https://anupamobserved.wordpress.com/2018/03/28/a-writing-revolution/)\n",
      "\n",
      "Starting Ragas evaluation...\n",
      "This may take a few minutes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8ca7f59e68a4e91b907ca6f187a177e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation completed!\n",
      "Results: {'answer_relevancy': 0.9332, 'faithfulness': 1.0000, 'llm_context_precision_without_reference': 1.0000}\n"
     ]
    }
   ],
   "source": [
    "# Sample question for evaluation\n",
    "sample_question = \"How can I write better?\"\n",
    "\n",
    "print(\"Creating evaluation dataset...\")\n",
    "evaluation_dataset_raw = create_evaluation_dataset(sample_question)\n",
    "print(f\"Created {len(evaluation_dataset_raw)} evaluation examples\")\n",
    "print('Here is the response: \\n\\n', evaluation_dataset_raw[0]['response']) \n",
    "perform_ragas_evaluation(evaluation_dataset_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f92b9808-ad7f-4ba5-bfe1-03aab1f724af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating evaluation dataset...\n",
      "\n",
      "Created 1 evaluation examples\n",
      "Here is the response: \n",
      "\n",
      " I don't know.\n",
      "\n",
      "No relevant blog posts found.\n",
      "Starting Ragas evaluation...\n",
      "This may take a few minutes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e53a89bc1214ffea0efde52f5284d67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation completed!\n",
      "Results: {'answer_relevancy': 0.0000, 'faithfulness': 0.0000, 'llm_context_precision_without_reference': 0.0000}\n"
     ]
    }
   ],
   "source": [
    "# Negative case for evaluation\n",
    "sample_question = \"What is the taste of an orange?\"\n",
    "\n",
    "print(\"Creating evaluation dataset...\")\n",
    "evaluation_dataset_raw = create_evaluation_dataset(sample_question)\n",
    "print(f\"Created {len(evaluation_dataset_raw)} evaluation examples\")\n",
    "print('Here is the response: \\n\\n', evaluation_dataset_raw[0]['response']) \n",
    "perform_ragas_evaluation(evaluation_dataset_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503d66d7-51c6-4b5c-84c4-f5ddd610540d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
